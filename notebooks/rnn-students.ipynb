{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Простейшая рекуррентная сеть\n",
    "В этом ноутбуке мы пройдемся по основам работы с RNN. Сегодня займемся задачей генерации текста. "
   ],
   "id": "39230c0c125c7b87"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:09:04.111638Z",
     "start_time": "2024-12-03T09:09:03.091754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "from typing import Iterable, Tuple\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "3d0372f458104003",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "В качестве обучающего датасета возьмем набор из 120 тысяч анекдотов на русском языке. \n",
    "[Ссылка на данные](https://archive.org/download/120_tysyach_anekdotov) и [пост на хабре про тематическое моделирование](https://habr.com/ru/companies/otus/articles/723306/)"
   ],
   "id": "2b01304ed592939b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:09:04.244316Z",
     "start_time": "2024-12-03T09:09:04.121257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(r\"../additional_materials/anek_djvu.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "text[118:500]"
   ],
   "id": "531fd687e99d2657",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|startoftext|>Друзья мои, чтобы соответствовать вам, я готов сделать над собой усилие и стать лучше. Но тогда и вы станьте немного хуже!\\n\\n<|startoftext|>- Люся, ты все еще хранишь мой подарок?- Да.- Я думал, ты выкинула все, что со мной связано.- Плюшевый мишка не виноват, что ты ебл@н...\\n\\n<|startoftext|>- А вот скажи честно, ты во сне храпишь?- Понятие не имею, вроде, нет. От со'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Мы не хотим моделировать все подряд, поэтому разобьем датасет на отдельные анекдоты.  ",
   "id": "d8dcf777d273cfb0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:09:04.339161Z",
     "start_time": "2024-12-03T09:09:04.337014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cut_data(text):\n",
    "    return text.replace(\"\\n\\n\", \"\").split(\"<|startoftext|>\")[1:]"
   ],
   "id": "424cc65ee5b26bf4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:09:04.430318Z",
     "start_time": "2024-12-03T09:09:04.379801Z"
    }
   },
   "cell_type": "code",
   "source": "cut_text = cut_data(text)",
   "id": "eb95ad63654b216f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:09:04.482683Z",
     "start_time": "2024-12-03T09:09:04.479417Z"
    }
   },
   "cell_type": "code",
   "source": "cut_text[1:6]",
   "id": "e3673ed32e7902a9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Друзья мои, чтобы соответствовать вам, я готов сделать над собой усилие и стать лучше. Но тогда и вы станьте немного хуже!',\n",
       " '- Люся, ты все еще хранишь мой подарок?- Да.- Я думал, ты выкинула все, что со мной связано.- Плюшевый мишка не виноват, что ты ебл@н...',\n",
       " '- А вот скажи честно, ты во сне храпишь?- Понятие не имею, вроде, нет. От собственного храпа по крайней мере еще ни разу не просыпался.- Ну, так у жены спроси.- А жена и подавно не знает. У нее странная привычка после замужества возникла: как спать ложится - беруши вставляет.',\n",
       " 'Поссорилась с мужем. Пока он спал, я мысленно развелась с ним, поделила имущество, переехала, поняла, что жить без него не могу, дала последний шанс, вернулась. В итоге, ложусь спать уже счастливой женщиной.',\n",
       " 'Если тебя посещают мысли о смерти - это еще полбеды. Беда - это когда смерть посещают мысли о тебе...']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Сделаем для начала самую простую модель с токенами на уровне символов. Это значит, что каждому символу в тексте ставится в соответствие некоторое число. Некоторые способы токенизации используют части слов или, наоборот, части бинарного представления текста.",
   "id": "a830ce525a24ee5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:09:04.956295Z",
     "start_time": "2024-12-03T09:09:04.599199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unique_chars = tuple(set(text))\n",
    "int2char = dict(enumerate(unique_chars))\n",
    "char2int = {ch: ii for ii, ch in int2char.items()}\n"
   ],
   "id": "a6f1294f7ea92087",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Напишем функции для энкодинга и декодинга нашего текста. Они будут преобразовывать список символов в список чисел и обратно.",
   "id": "85faff74d7ae54ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:09:04.964798Z",
     "start_time": "2024-12-03T09:09:04.962689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode(sentence, vocab):\n",
    "    return [vocab[sys] for sys in sentence] # List of ints \n",
    "\n",
    "def decode(tokens, vocab):\n",
    "    return [vocab[toc] for toc in tokens]# list of strings"
   ],
   "id": "83b99e93ea732ddd",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:09:05.065842Z",
     "start_time": "2024-12-03T09:09:05.062105Z"
    }
   },
   "cell_type": "code",
   "source": "encode(cut_text[0], char2int)",
   "id": "430856c287798779",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[121,\n",
       " 164,\n",
       " 172,\n",
       " 53,\n",
       " 204,\n",
       " 164,\n",
       " 35,\n",
       " 202,\n",
       " 190,\n",
       " 45,\n",
       " 194,\n",
       " 149,\n",
       " 136,\n",
       " 172,\n",
       " 138,\n",
       " 35,\n",
       " 87,\n",
       " 149,\n",
       " 164,\n",
       " 35,\n",
       " 173,\n",
       " 172,\n",
       " 164,\n",
       " 66,\n",
       " 164,\n",
       " 35,\n",
       " 111,\n",
       " 77,\n",
       " 142,\n",
       " 2,\n",
       " 7,\n",
       " 164,\n",
       " 111,\n",
       " 35,\n",
       " 7,\n",
       " 190,\n",
       " 59,\n",
       " 136,\n",
       " 2,\n",
       " 190,\n",
       " 194,\n",
       " 149,\n",
       " 173,\n",
       " 89,\n",
       " 35,\n",
       " 173,\n",
       " 190,\n",
       " 45,\n",
       " 136,\n",
       " 45,\n",
       " 136,\n",
       " 35,\n",
       " 95,\n",
       " 194,\n",
       " 7,\n",
       " 149,\n",
       " 2,\n",
       " 190,\n",
       " 172,\n",
       " 53,\n",
       " 7,\n",
       " 105,\n",
       " 45,\n",
       " 136,\n",
       " 35,\n",
       " 204,\n",
       " 172,\n",
       " 190,\n",
       " 66,\n",
       " 136,\n",
       " 24,\n",
       " 190,\n",
       " 45,\n",
       " 136,\n",
       " 38,\n",
       " 35,\n",
       " 11,\n",
       " 190,\n",
       " 204,\n",
       " 35,\n",
       " 66,\n",
       " 173,\n",
       " 194,\n",
       " 35,\n",
       " 77,\n",
       " 2,\n",
       " 164,\n",
       " 16,\n",
       " 88,\n",
       " 45,\n",
       " 190,\n",
       " 7,\n",
       " 164,\n",
       " 138,\n",
       " 35,\n",
       " 59,\n",
       " 172,\n",
       " 136,\n",
       " 7,\n",
       " 74]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Просто представления символов в виде числа не подходят для обучения моделей. На выходе должны быть вероятности всех возможных токенов из словаря. Поэтому модели удобно учить с помощью энтропии. К тому же, токены часто преобразуют из исходного представления в эмбеддинги, которые также позволяют получить более удобное представление в высокоразмерном пространстве. \n",
    "\n",
    "В итоге векторы в модели выглядят следующим образом:\n",
    "![alt_text](../additional_materials/images/char_rnn.jfif)\n",
    "\n",
    "Задание: реализуйте метод, который преобразует батч в бинарное представление."
   ],
   "id": "d2eeb4e360370b9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:09:05.553252Z",
     "start_time": "2024-12-03T09:09:05.550481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def one_hot_encode(int_words: torch.Tensor, vocab_size: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Encodes a batch of sentences (integer indices) into binary one-hot representation.\n",
    "    \n",
    "    Args:\n",
    "        int_words (torch.Tensor): Tensor of size (batch_size, seq_len) containing word indices.\n",
    "        vocab_size (int): Size of the vocabulary.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: One-hot encoded tensor of size (batch_size, seq_len, vocab_size).\n",
    "    \"\"\"\n",
    "    words_one_hot = torch.zeros(\n",
    "        (int_words.numel(), vocab_size), dtype=torch.float32, device=int_words.device\n",
    "    )\n",
    "    words_one_hot[torch.arange(words_one_hot.shape[0]), int_words.flatten().long()] = 1.0\n",
    "    words_one_hot = words_one_hot.reshape((*int_words.shape, vocab_size))\n",
    "    return words_one_hot\n"
   ],
   "id": "2c0cd279cb1b4448",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Проверьте ваш код.",
   "id": "b6f4f76432e7d0eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:09:06.344553Z",
     "start_time": "2024-12-03T09:09:06.339169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_seq = torch.tensor([[2, 6, 4, 1], [0,3, 2, 4]])\n",
    "test_one_hot = one_hot_encode(test_seq, 8)\n",
    "\n",
    "print(test_one_hot)"
   ],
   "id": "ee4a6dcafff3d37d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Однако, наши последовательности на самом деле разной длины. Как же объединить их в батч?",
   "id": "b3d89f1869ad4071"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Реализуем два необходимых класса: \n",
    "- токенайзер, который будет брать текст, кодировать и декодировать символы. Еще одно, что будет реализовано там - добавлено несколько специальных символов (паддинг, конец последовательности, начало последовательности).\n",
    "- Датасет, который будет брать набор шуток, используя токенайзер, строить эмбеддинги и дополнять последовательность до максимальной длины."
   ],
   "id": "67a3f3a5038e7da6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:09:06.983455Z",
     "start_time": "2024-12-03T09:09:06.976528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, cut_text, max_len: int = 512):\n",
    "        self.text = cut_text\n",
    "        self.max_len = max_len\n",
    "        self.specials = ['<pad>', '<bos>', '<eos>']\n",
    "        unique_chars = set()\n",
    "        for s in self.text:\n",
    "            unique_chars.update(s)\n",
    "        self.int2char = dict(enumerate(tuple(unique_chars)))\n",
    "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
    "        self._add_special(\"<pad>\")\n",
    "        self._add_special('<bos>')\n",
    "        self._add_special('<eos>')\n",
    "    \n",
    "    def _add_special(self, symbol) -> None:\n",
    "        # add special characters to yuor dicts\n",
    "        sym_num = len(self.char2int)\n",
    "        self.char2int[symbol] = sym_num\n",
    "        self.int2char[sym_num] = symbol\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.int2char) # your code\n",
    "        \n",
    "    def decode_symbol(self, el):\n",
    "        return self.int2char[el]\n",
    "        \n",
    "    def encode_symbol(self, el):\n",
    "        return self.char2int[el]\n",
    "        \n",
    "    def str_to_idx(self, chars):\n",
    "        return [self.char2int[sym] for sym in chars] # str -> list[int]\n",
    "\n",
    "    def idx_to_str(self, idx):\n",
    "        return [self.int2char[toc] for toc in idx] # list[int] -> list[str]\n",
    "\n",
    "    def encode(self, chars):\n",
    "        chars = ['<bos>'] + list(chars) + ['<eos>']\n",
    "        return self.str_to_idx(chars)\n",
    "\n",
    "    def decode(self, idx):\n",
    "        chars = self.idx_to_str(idx)\n",
    "        return \"\".join(chars) # make string from list"
   ],
   "id": "7bfa0495471297cb",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:35:38.282288Z",
     "start_time": "2024-12-03T09:35:38.278590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class JokesDataset(Dataset):\n",
    "    def __init__(self, tokenizer, cut_text, max_len: int = 512):\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.cut_text = cut_text\n",
    "        self.pad_index = self.tokenizer.encode_symbol(\"<pad>\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.cut_text)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.cut_text[idx]\n",
    "        encoded = self.tokenizer.encode(text)\n",
    "        encoded = encoded[:self.max_len]  # Ограничиваем длину\n",
    "        input_sequence = torch.full((self.max_len,), self.pad_index, dtype=torch.long)\n",
    "        target_sequence = torch.full((self.max_len,), self.pad_index, dtype=torch.long)\n",
    "        \n",
    "        # Заполняем входную и целевую последовательность\n",
    "        input_sequence[:len(encoded)] = torch.tensor(encoded[:])\n",
    "        target_sequence[:len(encoded)-1] = torch.tensor(encoded[1:])\n",
    "        return input_sequence, target_sequence"
   ],
   "id": "db7a784a2a139f4",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:35:38.844408Z",
     "start_time": "2024-12-03T09:35:38.469586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = Tokenizer(cut_text)\n",
    "dataset = JokesDataset(tokenizer, cut_text, 512)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ],
   "id": "616e89b2b5ef727e",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:35:38.912628Z",
     "start_time": "2024-12-03T09:35:38.909668Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.vocab_size",
   "id": "dbfdd1f3cf6c8c19",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Вопрос: А как бы мы должны были разделять данные на последовательности и батчи в случае, если бы использовался сплошной текст?",
   "id": "26851c2eafdff047"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:35:41.107636Z",
     "start_time": "2024-12-03T09:35:41.072796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for batch in dataloader:\n",
    "    break\n",
    "batch[1].shape"
   ],
   "id": "141707a3641af788",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([213, 149,  35,   7, 163,  45, 135,   7, 188,  94, 135, 135,  35, 171,\n",
      "         87,  86,  24, 135, 143,  35, 188,   7, 148, 135, 202, 163,   2,   2,\n",
      "         87,  77,  94, 135, 163,   7, 192,   2,  35, 172,   2, 192,  16, 135,\n",
      "         35, 202, 171, 163,  87,   7, 163,  66,  35,  75,  35,  77, 163,  59,\n",
      "        192,  16, 135, 171,  35, 163,  68,  68,  24, 163,   2,  38, 214, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212]) tensor([149,  35,   7, 163,  45, 135,   7, 188,  94, 135, 135,  35, 171,  87,\n",
      "         86,  24, 135, 143,  35, 188,   7, 148, 135, 202, 163,   2,   2,  87,\n",
      "         77,  94, 135, 163,   7, 192,   2,  35, 172,   2, 192,  16, 135,  35,\n",
      "        202, 171, 163,  87,   7, 163,  66,  35,  75,  35,  77, 163,  59, 192,\n",
      "         16, 135, 171,  35, 163,  68,  68,  24, 163,   2,  38, 214, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212])\n",
      "tensor([213,  17,  86, 188, 172, 148, 171, 135,  66, 104, 143,  35,  77, 188,\n",
      "         77, 188,  24, 188,  35,  77, 163,  16,  35, 163, 202,   7, 188,  45,\n",
      "        135,  35,   2, 163,  16,  16, 163,  45, 188, 128,  75,  35,  23, 188,\n",
      "         24, 202, 188, 137,  35, 202, 148, 163,  72,  35,  23, 188, 171,  53,\n",
      "         86, 135, 202,  72,  75,  35, 146, 192, 148,  74,  75,  35, 179,  35,\n",
      "        202, 148, 163,  72, 214, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212]) tensor([ 17,  86, 188, 172, 148, 171, 135,  66, 104, 143,  35,  77, 188,  77,\n",
      "        188,  24, 188,  35,  77, 163,  16,  35, 163, 202,   7, 188,  45, 135,\n",
      "         35,   2, 163,  16,  16, 163,  45, 188, 128,  75,  35,  23, 188,  24,\n",
      "        202, 188, 137,  35, 202, 148, 163,  72,  35,  23, 188, 171,  53,  86,\n",
      "        135, 202,  72,  75,  35, 146, 192, 148,  74,  75,  35, 179,  35, 202,\n",
      "        148, 163,  72, 214, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212])\n",
      "tensor([213, 149,  35, 172,  66,  88, 200, 135,  35, 172,  35,   3,  77, 135,\n",
      "         16, 192,  45, 135, 192, 143,  35, 172,  66, 135,   7, 163,  15, 163,\n",
      "         35,  15,   2, 135,  77,  77, 188,  35,  66,  35, 193, 202,   2, 188,\n",
      "        135,   7,  87,  35,  87, 111, 192,  35, 200, 188,  66, 192, 200, 192,\n",
      "          7, 188,  35,  77, 188,   2, 148, 135,  88,  35,  45, 188,   2, 171,\n",
      "        192,  66, 104, 170,  35,  77, 163,  66,  88, 200, 163, 202,  35, 172,\n",
      "         35,  66, 104,   2, 192, 200, 163,  45,  35,  77, 163,  16,  35,  77,\n",
      "         88, 148, 188,  86, 163, 202,  38, 214, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212]) tensor([149,  35, 172,  66,  88, 200, 135,  35, 172,  35,   3,  77, 135,  16,\n",
      "        192,  45, 135, 192, 143,  35, 172,  66, 135,   7, 163,  15, 163,  35,\n",
      "         15,   2, 135,  77,  77, 188,  35,  66,  35, 193, 202,   2, 188, 135,\n",
      "          7,  87,  35,  87, 111, 192,  35, 200, 188,  66, 192, 200, 192,   7,\n",
      "        188,  35,  77, 188,   2, 148, 135,  88,  35,  45, 188,   2, 171, 192,\n",
      "         66, 104, 170,  35,  77, 163,  66,  88, 200, 163, 202,  35, 172,  35,\n",
      "         66, 104,   2, 192, 200, 163,  45,  35,  77, 163,  16,  35,  77,  88,\n",
      "        148, 188,  86, 163, 202,  38, 214, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212])\n",
      "tensor([213,  70, 171,  88,  16,  88,  35,   7, 188,  35, 148, 163, 137,  35,\n",
      "        202, 188, 202,  35,   3, 148, 163,  45,  35,  15, 163,  16,  87,  35,\n",
      "          7, 192,  35,  77, 163,  66, 192, 200, 171, 163,  35, 120,   2, 188,\n",
      "         45,  77,  87,  35, 135,  35,   1,  87,  59, 188, 143, 172,  87, 137,\n",
      "         35, 210, 104, 111, 135, 143,  35, 135, 200,  35, 110,  89,  66, 188,\n",
      "          7,  87,  24, 192, 202, 110,  35,   2, 192,  24, 135, 171,  35,  77,\n",
      "        192,   2, 192, 202,   2, 188, 172, 135, 148,  53, 172,  88,  38, 214,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212]) tensor([ 70, 171,  88,  16,  88,  35,   7, 188,  35, 148, 163, 137,  35, 202,\n",
      "        188, 202,  35,   3, 148, 163,  45,  35,  15, 163,  16,  87,  35,   7,\n",
      "        192,  35,  77, 163,  66, 192, 200, 171, 163,  35, 120,   2, 188,  45,\n",
      "         77,  87,  35, 135,  35,   1,  87,  59, 188, 143, 172,  87, 137,  35,\n",
      "        210, 104, 111, 135, 143,  35, 135, 200,  35, 110,  89,  66, 188,   7,\n",
      "         87,  24, 192, 202, 110,  35,   2, 192,  24, 135, 171,  35,  77, 192,\n",
      "          2, 192, 202,   2, 188, 172, 135, 148,  53, 172,  88,  38, 214, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212])\n",
      "tensor([213,  75,  35, 165, 163,  86, 192,  45,  87,  35, 111, 135, 148, 192,\n",
      "        171, 135,  35, 193, 202,   2, 188, 135,   7, 104,  35,  66, 104, 172,\n",
      "        148,  87,  77, 188,  71, 148,  35,  77,   2, 163, 148, 135,  66,  35,\n",
      "         77,   2, 135, 172, 163, 192,  16, 135,   7, 192,   7, 135,  88,  35,\n",
      "         11,   2, 104,  45, 188,  35, 202,  35, 210, 163, 172, 172, 135, 135,\n",
      "         72,  75,  35, 114, 188,  66, 135,  16,  87,  71, 148,  38, 214, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212]) tensor([ 75,  35, 165, 163,  86, 192,  45,  87,  35, 111, 135, 148, 192, 171,\n",
      "        135,  35, 193, 202,   2, 188, 135,   7, 104,  35,  66, 104, 172, 148,\n",
      "         87,  77, 188,  71, 148,  35,  77,   2, 163, 148, 135,  66,  35,  77,\n",
      "          2, 135, 172, 163, 192,  16, 135,   7, 192,   7, 135,  88,  35,  11,\n",
      "          2, 104,  45, 188,  35, 202,  35, 210, 163, 172, 172, 135, 135,  72,\n",
      "         75,  35, 114, 188,  66, 135,  16,  87,  71, 148,  38, 214, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212])\n",
      "tensor([213, 146, 188,  35, 172, 188, 143, 148, 192, 128,  75,  35, 165,   2,\n",
      "        135,  66, 192, 148,  74,  35, 120, 104,  35, 202, 171, 188, 172, 172,\n",
      "          7, 104, 143,  74,  35, 165, 163, 200,   7, 188, 202, 163,  45, 135,\n",
      "         45, 172,  88,  72,  75,  35, 165,   2, 135,  66, 192, 148,  38,  35,\n",
      "         44,  35, 200,   7, 188,  71,  38,  35, 146, 192, 148,  38, 214, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212]) tensor([146, 188,  35, 172, 188, 143, 148, 192, 128,  75,  35, 165,   2, 135,\n",
      "         66, 192, 148,  74,  35, 120, 104,  35, 202, 171, 188, 172, 172,   7,\n",
      "        104, 143,  74,  35, 165, 163, 200,   7, 188, 202, 163,  45, 135,  45,\n",
      "        172,  88,  72,  75,  35, 165,   2, 135,  66, 192, 148,  38,  35,  44,\n",
      "         35, 200,   7, 188,  71,  38,  35, 146, 192, 148,  38, 214, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212])\n",
      "tensor([213,  75,  35,  89,  35,  86, 192,  15, 163,  35, 148, 104,  35,  16,\n",
      "        163,  59, 135, 171, 172,  88,  35,  66,  35, 172,  66, 163, 135,  35,\n",
      "        140, 195,  72,  74,  75,  35,  89, 200,  59, 192, 111, 188, 171,  35,\n",
      "        172,  66, 188,  16,  53,  59, 104, 137,  35, 135,  77, 163, 148, 192,\n",
      "        202, 135, 137,  35, 172,  77, 135,   7, 163,  15,   2, 104, 200, 163,\n",
      "         66,  38, 214, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212]) tensor([ 75,  35,  89,  35,  86, 192,  15, 163,  35, 148, 104,  35,  16, 163,\n",
      "         59, 135, 171, 172,  88,  35,  66,  35, 172,  66, 163, 135,  35, 140,\n",
      "        195,  72,  74,  75,  35,  89, 200,  59, 192, 111, 188, 171,  35, 172,\n",
      "         66, 188,  16,  53,  59, 104, 137,  35, 135,  77, 163, 148, 192, 202,\n",
      "        135, 137,  35, 172,  77, 135,   7, 163,  15,   2, 104, 200, 163,  66,\n",
      "         38, 214, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212])\n",
      "tensor([213, 149,  35,  77, 192,   2, 192,  66, 192,   2,   7,  87, 148, 163,\n",
      "         45,  35, 163,  59, 112, 192, 172, 148,  66, 192,  35,  66, 172, 192,\n",
      "         35, 172, 171, 135,  66, 202, 135,  35,  75,  35,   3, 148, 163,  35,\n",
      "         77, 163,  16, 163,   7, 202, 135,  38, 214, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212]) tensor([149,  35,  77, 192,   2, 192,  66, 192,   2,   7,  87, 148, 163,  45,\n",
      "         35, 163,  59, 112, 192, 172, 148,  66, 192,  35,  66, 172, 192,  35,\n",
      "        172, 171, 135,  66, 202, 135,  35,  75,  35,   3, 148, 163,  35,  77,\n",
      "        163,  16, 163,   7, 202, 135,  38, 214, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212])\n",
      "tensor([213,  75,  35,  11, 188, 202,  35, 172, 192,  45,  53,  88,  72,  75,\n",
      "         35,  83, 188, 137,  35, 200,   7, 188, 192,  24,  53, 137,  35, 192,\n",
      "        172, 148,  53,  35,  77,   2, 163,  59, 171, 192,  45, 104,  38,  35,\n",
      "        149,  86, 192,   2, 188,  35,  87,  35, 111, 192,   7, 104,  35,  66,\n",
      "         35,  77, 163, 172, 148, 192, 171, 135,  35,   7, 188,  24, 192, 171,\n",
      "         35,  15, 188, 192,  86,   7, 104, 143,  35, 202, 171,  71,  86,  38,\n",
      "         35,  23, 163, 111, 192, 148, 137,  35, 163,   7, 188,  35,  45,   7,\n",
      "        192,  35, 172,  35,  45, 188,  24, 135,   7, 135, 172, 148, 163,  45,\n",
      "         35, 135, 200,  45, 192,   7,  88, 192, 148,  72,  75,  35, 146,  87,\n",
      "         35, 148, 104,  35,  16, 188, 192,  24,  53,  74,  35,  44,  35,  87,\n",
      "         35, 172,  66, 163, 192, 143,  35,  66,  86, 192,   2, 188,  35,  45,\n",
      "        188,  24, 135,   7, 135, 172, 148, 188,  35,   7, 188,  24, 192, 171,\n",
      "         74,  35, 120, 188, 202,  35,  86, 148, 163,  35, 111, 192, 137,  35,\n",
      "        163,   7, 188,  35,  45,   7, 192,  35, 172,  35,  77, 188,   2, 163,\n",
      "         66, 163, 200, 163,  45,  35, 135, 200,  45, 192,   7,  88, 192, 148,\n",
      "         72, 214, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212]) tensor([ 75,  35,  11, 188, 202,  35, 172, 192,  45,  53,  88,  72,  75,  35,\n",
      "         83, 188, 137,  35, 200,   7, 188, 192,  24,  53, 137,  35, 192, 172,\n",
      "        148,  53,  35,  77,   2, 163,  59, 171, 192,  45, 104,  38,  35, 149,\n",
      "         86, 192,   2, 188,  35,  87,  35, 111, 192,   7, 104,  35,  66,  35,\n",
      "         77, 163, 172, 148, 192, 171, 135,  35,   7, 188,  24, 192, 171,  35,\n",
      "         15, 188, 192,  86,   7, 104, 143,  35, 202, 171,  71,  86,  38,  35,\n",
      "         23, 163, 111, 192, 148, 137,  35, 163,   7, 188,  35,  45,   7, 192,\n",
      "         35, 172,  35,  45, 188,  24, 135,   7, 135, 172, 148, 163,  45,  35,\n",
      "        135, 200,  45, 192,   7,  88, 192, 148,  72,  75,  35, 146,  87,  35,\n",
      "        148, 104,  35,  16, 188, 192,  24,  53,  74,  35,  44,  35,  87,  35,\n",
      "        172,  66, 163, 192, 143,  35,  66,  86, 192,   2, 188,  35,  45, 188,\n",
      "         24, 135,   7, 135, 172, 148, 188,  35,   7, 188,  24, 192, 171,  74,\n",
      "         35, 120, 188, 202,  35,  86, 148, 163,  35, 111, 192, 137,  35, 163,\n",
      "          7, 188,  35,  45,   7, 192,  35, 172,  35,  77, 188,   2, 163,  66,\n",
      "        163, 200, 163,  45,  35, 135, 200,  45, 192,   7,  88, 192, 148,  72,\n",
      "        214, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212])\n",
      "tensor([213, 120, 192, 171, 192,  68, 163,   7,   7, 104, 143,  35, 200,  66,\n",
      "        163,   7, 163, 202, 128,  75,  35, 179, 171, 192, 137,  35, 146, 188,\n",
      "        148, 188,  24,  87,  35,  45, 163, 111,   7, 163,  72, 146, 188,  35,\n",
      "         16,   2,  87,  15, 163,  45,  35, 202, 163,   7,  94, 192,  35,  16,\n",
      "        163, 171,  15, 188,  88,  35,  77, 188,  87, 200, 188, 128,  75,  35,\n",
      "        179,  35,  86, 163, 137,  35, 170, 163,   2, 163,  24, 188,  88,  35,\n",
      "        135,  16, 192,  88,  74, 214, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212]) tensor([120, 192, 171, 192,  68, 163,   7,   7, 104, 143,  35, 200,  66, 163,\n",
      "          7, 163, 202, 128,  75,  35, 179, 171, 192, 137,  35, 146, 188, 148,\n",
      "        188,  24,  87,  35,  45, 163, 111,   7, 163,  72, 146, 188,  35,  16,\n",
      "          2,  87,  15, 163,  45,  35, 202, 163,   7,  94, 192,  35,  16, 163,\n",
      "        171,  15, 188,  88,  35,  77, 188,  87, 200, 188, 128,  75,  35, 179,\n",
      "         35,  86, 163, 137,  35, 170, 163,   2, 163,  24, 188,  88,  35, 135,\n",
      "         16, 192,  88,  74, 214, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212])\n",
      "tensor([213,  23,  87, 111, 135, 202,  35,  77, 163, 200,  16,   7, 163,  35,\n",
      "          7, 163,  86,  53,  71,  35,  66, 163, 200,  66,   2, 188, 112, 188,\n",
      "        192, 148, 172,  88,  35,  16, 163,  45, 163, 143,  38,  35,   0,  15,\n",
      "        163,  35, 111, 192,   7, 188,  35, 172,  35, 172, 163, 172, 192,  16,\n",
      "        202, 188,  45, 135,  35,  59, 163, 171, 148, 188, 192, 148,  35,   7,\n",
      "        188,  35, 202,  87, 170,   7, 192,  38,  75,  35,  70,  16, 192,  35,\n",
      "        148, 104, 137,  35, 172,  66, 163, 171, 163,  86,  53, 137,  35, 148,\n",
      "        188, 202,  35,  16, 163, 171,  15, 163,  35,  59, 104, 171,  72,  75,\n",
      "         35, 193,  35,  77,   2, 135,  88, 148, 192, 171,  88,  38, 149, 172,\n",
      "        192,  35, 111, 192,   7, 112, 135,   7, 104,  35,  66,  35, 163,  16,\n",
      "        135,   7,  35,  15, 163, 171, 163, 172, 128,  75,  35, 179, 170,  35,\n",
      "        148, 104,  35, 135, 200,  66,   2, 188, 112, 192,   7, 192,  94,  74,\n",
      "        214, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212]) tensor([ 23,  87, 111, 135, 202,  35,  77, 163, 200,  16,   7, 163,  35,   7,\n",
      "        163,  86,  53,  71,  35,  66, 163, 200,  66,   2, 188, 112, 188, 192,\n",
      "        148, 172,  88,  35,  16, 163,  45, 163, 143,  38,  35,   0,  15, 163,\n",
      "         35, 111, 192,   7, 188,  35, 172,  35, 172, 163, 172, 192,  16, 202,\n",
      "        188,  45, 135,  35,  59, 163, 171, 148, 188, 192, 148,  35,   7, 188,\n",
      "         35, 202,  87, 170,   7, 192,  38,  75,  35,  70,  16, 192,  35, 148,\n",
      "        104, 137,  35, 172,  66, 163, 171, 163,  86,  53, 137,  35, 148, 188,\n",
      "        202,  35,  16, 163, 171,  15, 163,  35,  59, 104, 171,  72,  75,  35,\n",
      "        193,  35,  77,   2, 135,  88, 148, 192, 171,  88,  38, 149, 172, 192,\n",
      "         35, 111, 192,   7, 112, 135,   7, 104,  35,  66,  35, 163,  16, 135,\n",
      "          7,  35,  15, 163, 171, 163, 172, 128,  75,  35, 179, 170,  35, 148,\n",
      "        104,  35, 135, 200,  66,   2, 188, 112, 192,   7, 192,  94,  74, 214,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212])\n",
      "tensor([213,  96, 163,   2, 163,  24, 163,  35,  59, 104, 148,  53,  35,  68,\n",
      "          2, 135, 171, 188,   7, 172, 192,   2, 163,  45,  74,  35,  83, 192,\n",
      "          7,  53,  35,  77,   2, 163,  24, 192, 171,  35,  66,  77,  87, 172,\n",
      "        148,  87,  71,  72,  35, 114, 188,  59, 192, 143, 137,  35,   3, 148,\n",
      "        163,  35,  59, 104, 171,  35,  66, 104, 170, 163,  16,   7, 163, 143,\n",
      "         38, 214, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212]) tensor([ 96, 163,   2, 163,  24, 163,  35,  59, 104, 148,  53,  35,  68,   2,\n",
      "        135, 171, 188,   7, 172, 192,   2, 163,  45,  74,  35,  83, 192,   7,\n",
      "         53,  35,  77,   2, 163,  24, 192, 171,  35,  66,  77,  87, 172, 148,\n",
      "         87,  71,  72,  35, 114, 188,  59, 192, 143, 137,  35,   3, 148, 163,\n",
      "         35,  59, 104, 171,  35,  66, 104, 170, 163,  16,   7, 163, 143,  38,\n",
      "        214, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212])\n",
      "tensor([213,   0, 172, 171, 135,  35,  77, 163, 172, 135,  16, 192, 148,  53,\n",
      "         35,   7, 188,  35,  24, 202,  87,   2, 192,  35, 171,  53,  66, 188,\n",
      "         35,  75,  35,  77,   2, 163, 143,  16, 192, 148,  35,  15, 192,  45,\n",
      "        163,   2,   2, 163, 143, 137,  35, 188,  35,  77, 163, 172, 135,  16,\n",
      "        192, 148,  53,  35,   7, 188,  35, 111, 135,  66, 163,  45,  35, 171,\n",
      "         53,  66, 192,  35,  75,  35,  77,   2, 163, 143,  16, 192, 148,  35,\n",
      "          7, 192,  77,   2, 163, 170, 163,  16, 135,  45, 163, 172, 148,  53,\n",
      "         35,  45, 163,  86, 192,  66, 104, 170,  35,  77,  87, 148, 192, 143,\n",
      "         38, 214, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212]) tensor([  0, 172, 171, 135,  35,  77, 163, 172, 135,  16, 192, 148,  53,  35,\n",
      "          7, 188,  35,  24, 202,  87,   2, 192,  35, 171,  53,  66, 188,  35,\n",
      "         75,  35,  77,   2, 163, 143,  16, 192, 148,  35,  15, 192,  45, 163,\n",
      "          2,   2, 163, 143, 137,  35, 188,  35,  77, 163, 172, 135,  16, 192,\n",
      "        148,  53,  35,   7, 188,  35, 111, 135,  66, 163,  45,  35, 171,  53,\n",
      "         66, 192,  35,  75,  35,  77,   2, 163, 143,  16, 192, 148,  35,   7,\n",
      "        192,  77,   2, 163, 170, 163,  16, 135,  45, 163, 172, 148,  53,  35,\n",
      "         45, 163,  86, 192,  66, 104, 170,  35,  77,  87, 148, 192, 143,  38,\n",
      "        214, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212])\n",
      "tensor([213, 165, 163,  16,  35, 171, 192, 111, 188,  86, 135, 143,  35, 202,\n",
      "        188,  45, 192,   7,  53,  35,  45, 104,  35,  66, 172, 192,  15,  16,\n",
      "        188,  35,  87, 172,  77, 192, 192,  45,  38, 214, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212]) tensor([165, 163,  16,  35, 171, 192, 111, 188,  86, 135, 143,  35, 202, 188,\n",
      "         45, 192,   7,  53,  35,  45, 104,  35,  66, 172, 192,  15,  16, 188,\n",
      "         35,  87, 172,  77, 192, 192,  45,  38, 214, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212])\n",
      "tensor([213, 165,   2, 163,  15,   2, 188,  45,  45, 135, 172, 148,  35,   7,\n",
      "        188,  77, 135, 172, 188, 171,  35,  77,   2, 135, 171, 163, 111, 192,\n",
      "          7, 135, 192,  35,  16, 171,  88,  35,  77, 163,  16,  59, 163,   2,\n",
      "        188,  35, 135,  16, 192, 188, 171,  53,   7, 104, 170,  35, 111, 192,\n",
      "          7,  38,  35, 149,  66, 163,  16, 135, 148,  35,  16, 188,   7,   7,\n",
      "        104, 192, 128,  75,  35,  96, 163,  86,  87,  35,   7, 192,  66, 104,\n",
      "        172, 163, 202,  87,  71,  35,  59,   2,  71,   7, 192, 148, 202,  87,\n",
      "        137,  35,   7, 192,  77,   2, 135, 170, 163, 148, 171, 135,  66,  87,\n",
      "         71, 137,  35,  45, 163, 171,  86, 188, 171, 135,  66,  87,  71, 137,\n",
      "         35,  87,  45, 192,  71, 112,  87,  71,  35,  77, 171, 188,  66, 188,\n",
      "        148,  53,  38,  11, 163,  45,  77,  53,  71, 148, 192,   2,  35,  66,\n",
      "        104,  66, 163,  16, 135, 148,  35,   2, 192, 202, 163,  45, 192,   7,\n",
      "         16, 188,  94, 135, 135, 128,  75,  35,  17, 188,  45, 202, 188,  35,\n",
      "         77, 135,   7,  15,  66, 135,   7, 188,  38, 214, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212]) tensor([165,   2, 163,  15,   2, 188,  45,  45, 135, 172, 148,  35,   7, 188,\n",
      "         77, 135, 172, 188, 171,  35,  77,   2, 135, 171, 163, 111, 192,   7,\n",
      "        135, 192,  35,  16, 171,  88,  35,  77, 163,  16,  59, 163,   2, 188,\n",
      "         35, 135,  16, 192, 188, 171,  53,   7, 104, 170,  35, 111, 192,   7,\n",
      "         38,  35, 149,  66, 163,  16, 135, 148,  35,  16, 188,   7,   7, 104,\n",
      "        192, 128,  75,  35,  96, 163,  86,  87,  35,   7, 192,  66, 104, 172,\n",
      "        163, 202,  87,  71,  35,  59,   2,  71,   7, 192, 148, 202,  87, 137,\n",
      "         35,   7, 192,  77,   2, 135, 170, 163, 148, 171, 135,  66,  87,  71,\n",
      "        137,  35,  45, 163, 171,  86, 188, 171, 135,  66,  87,  71, 137,  35,\n",
      "         87,  45, 192,  71, 112,  87,  71,  35,  77, 171, 188,  66, 188, 148,\n",
      "         53,  38,  11, 163,  45,  77,  53,  71, 148, 192,   2,  35,  66, 104,\n",
      "         66, 163,  16, 135, 148,  35,   2, 192, 202, 163,  45, 192,   7,  16,\n",
      "        188,  94, 135, 135, 128,  75,  35,  17, 188,  45, 202, 188,  35,  77,\n",
      "        135,   7,  15,  66, 135,   7, 188,  38, 214, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212])\n",
      "tensor([213, 127, 163, 171,  53,   7, 163, 143,  35, 163, 148,  35,  66, 172,\n",
      "        202,   2, 104, 148, 135,  88,  35, 163, 148, 202, 188, 200, 188, 171,\n",
      "        172,  88, 137,  35,  66, 104,  77, 135, 172, 188,   7,  35,  77, 163,\n",
      "         16,  35,   7, 188,  59, 171,  71,  16, 192,   7, 135, 192,  35,   2,\n",
      "        188, 143, 163,   7,   7, 163,  15, 163,  35,  77, 188, 148, 163, 171,\n",
      "        163,  15, 163, 188,   7, 188, 148, 163,  45, 188,  38, 214, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212]) tensor([127, 163, 171,  53,   7, 163, 143,  35, 163, 148,  35,  66, 172, 202,\n",
      "          2, 104, 148, 135,  88,  35, 163, 148, 202, 188, 200, 188, 171, 172,\n",
      "         88, 137,  35,  66, 104,  77, 135, 172, 188,   7,  35,  77, 163,  16,\n",
      "         35,   7, 188,  59, 171,  71,  16, 192,   7, 135, 192,  35,   2, 188,\n",
      "        143, 163,   7,   7, 163,  15, 163,  35,  77, 188, 148, 163, 171, 163,\n",
      "         15, 163, 188,   7, 188, 148, 163,  45, 188,  38, 214, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212, 212, 212, 212, 212])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 512])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:37:18.512787Z",
     "start_time": "2024-12-03T09:37:18.510015Z"
    }
   },
   "cell_type": "code",
   "source": "len(batch)",
   "id": "81cc33a5bb5e7022",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:36:26.207408Z",
     "start_time": "2024-12-03T09:36:26.202492Z"
    }
   },
   "cell_type": "code",
   "source": "batch[0][0]",
   "id": "6c5d2fe577add9d6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([213, 149,  35,   7, 163,  45, 135,   7, 188,  94, 135, 135,  35, 171,\n",
       "         87,  86,  24, 135, 143,  35, 188,   7, 148, 135, 202, 163,   2,   2,\n",
       "         87,  77,  94, 135, 163,   7, 192,   2,  35, 172,   2, 192,  16, 135,\n",
       "         35, 202, 171, 163,  87,   7, 163,  66,  35,  75,  35,  77, 163,  59,\n",
       "        192,  16, 135, 171,  35, 163,  68,  68,  24, 163,   2,  38, 214, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:36:35.644065Z",
     "start_time": "2024-12-03T09:36:35.638917Z"
    }
   },
   "cell_type": "code",
   "source": "batch[1][0]",
   "id": "6244708739fac4b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([149,  35,   7, 163,  45, 135,   7, 188,  94, 135, 135,  35, 171,  87,\n",
       "         86,  24, 135, 143,  35, 188,   7, 148, 135, 202, 163,   2,   2,  87,\n",
       "         77,  94, 135, 163,   7, 192,   2,  35, 172,   2, 192,  16, 135,  35,\n",
       "        202, 171, 163,  87,   7, 163,  66,  35,  75,  35,  77, 163,  59, 192,\n",
       "         16, 135, 171,  35, 163,  68,  68,  24, 163,   2,  38, 214, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212, 212, 212, 212, 212, 212, 212])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Теперь реализуем нашу модель. \n",
    "Необходимо следующее:\n",
    " - Используя токенайзер, задать размер словаря\n",
    " - Задать слой RNN с помощью torch.RNN. Доп.задание: создайте модель, используя слой LSTM.\n",
    " - Задать полносвязный слой с набором параметров: размерность ввода — n_hidden; размерность выхода — размер словаря. Этот слой преобразует состояние модели в логиты токенов.\n",
    " - Определить шаг forward, который будет использоваться при обучении\n",
    " - Определить метод init_hidden, который будет задавать начальное внутреннее состояние. Инициализировать будем нулями.\n",
    " - Определить метод inference, в котором будет происходить генерация последовательности из префикса. Здесь мы уже не используем явные логиты, а семплируем токены на их основе.\n"
   ],
   "id": "332b845f0335170d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:23:26.778315Z",
     "start_time": "2024-12-03T09:23:26.770056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from typing import Tuple\n",
    "\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer,\n",
    "        hidden_dim: int = 256,\n",
    "        num_layers: int = 2,\n",
    "        drop_prob: float = 0.5,\n",
    "        max_len: int = 512,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.drop_prob = drop_prob\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        # Токенизатор для кодирования и декодирования\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab_size = tokenizer.vocab_size # размер словаря\n",
    "        \n",
    "        # RNN (или LSTM) слой\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=self.vocab_size,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=self.drop_prob,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        \n",
    "        # Dropout для регуляризации\n",
    "        self.dropout = nn.Dropout(self.drop_prob)\n",
    "        \n",
    "        # Полносвязный слой: преобразует состояние RNN в логиты\n",
    "        self.fc = nn.Linear(self.hidden_dim, self.vocab_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, lengths: torch.Tensor) -> Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        # One-hot кодирование входной последовательности\n",
    "        x = one_hot_encode(x, vocab_size=self.vocab_size)\n",
    "        \n",
    "        # Упаковка последовательностей для эффективности\n",
    "        packed_embeds = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        # Прогон через LSTM\n",
    "        packed_outputs, hidden = self.rnn(packed_embeds)\n",
    "        \n",
    "        # Распаковка выхода обратно в тензор\n",
    "        outputs, _ = pad_packed_sequence(packed_outputs, batch_first=True)\n",
    "        \n",
    "        # Dropout для регуляризации\n",
    "        outputs = self.dropout(outputs)\n",
    "        \n",
    "        # Преобразование выхода RNN в логиты\n",
    "        logits = self.fc(outputs)\n",
    "        return logits, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size: int, device: str = \"cpu\") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Инициализация начального скрытого состояния нулями\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=device)\n",
    "        return h0, c0\n",
    "\n",
    "    def inference(self, prefix=\"\", device=\"cpu\"):\n",
    "        # Кодирование начального префикса\n",
    "        tokens = torch.tensor(self.tokenizer.encode(prefix), dtype=torch.long, device=device).unsqueeze(0)\n",
    "        tokens = tokens[:, :-1]\n",
    "        # Создание one-hot представления\n",
    "        inputs = one_hot_encode(tokens, vocab_size=self.vocab_size)\n",
    "        # Инициализация скрытого состояния\n",
    "        hidden = self.init_hidden(batch_size=1, device=device)\n",
    "        \n",
    "        # Генерация префикса\n",
    "        outputs, hidden = self.rnn(inputs, hidden)\n",
    "        logits = self.fc(outputs)\n",
    "        \n",
    "        # Семплирование токена\n",
    "        probs = torch.softmax(logits[:, -1, :], dim=-1)\n",
    "        new_token = torch.multinomial(probs, num_samples=1)\n",
    "        tokens = torch.cat([tokens, new_token], dim=1)\n",
    "        \n",
    "        # Остановка: достижение максимальной длины или EOS-токена\n",
    "        while tokens.size(1) < self.max_len and new_token.item() != self.tokenizer.encode_symbol('<eos>'):\n",
    "            inputs = one_hot_encode(tokens, vocab_size=self.vocab_size)\n",
    "            outputs, hidden = self.rnn(inputs, hidden)\n",
    "            logits = self.fc(outputs)\n",
    "            probs = torch.softmax(logits[:, -1, :], dim=-1)\n",
    "            new_token = torch.multinomial(probs, num_samples=1)\n",
    "            tokens = torch.cat([tokens, new_token], dim=1)\n",
    "        \n",
    "        # Декодирование в строку\n",
    "        return self.tokenizer.decode(tokens.squeeze().tolist())"
   ],
   "id": "6c975b508a3fc327",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Зададим параметры для обучения. Можете варьировать их, чтобы вам хватило ресурсов.",
   "id": "fdaa65b24ad49588"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:23:27.496443Z",
     "start_time": "2024-12-03T09:23:27.493667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 16\n",
    "seq_length = 512\n",
    "n_hidden = 128\n",
    "n_layers = 6\n",
    "drop_prob = 0.1\n",
    "lr = 0.1"
   ],
   "id": "db640af3cd71f8c9",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Напишите функцию для одного тренировочного шага. В этом ноутбуке сам процесс обучения модели достаточно тривиален, поэтому мы не будем использовать сложные функции для обучающего цикла. Вы же, однако, можете дописать их.",
   "id": "d1dee9492a0000d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:23:27.922287Z",
     "start_time": "2024-12-03T09:23:27.918816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def training_step(\n",
    "    model: CharRNN,\n",
    "    train_batch: Tuple[torch.Tensor, torch.Tensor],\n",
    "    vocab_size: int,\n",
    "    criterion: nn.Module,\n",
    "    optimizer,\n",
    "    device=\"cpu\"\n",
    ") -> torch.Tensor:\n",
    "    # Обнуляем градиенты\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Извлекаем данные из пакета\n",
    "    inputs, targets = train_batch\n",
    "    batch_size, seq_len = inputs.shape\n",
    "\n",
    "    # Переносим данные на нужное устройство (например, GPU)\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "    # Прямой проход через модель\n",
    "    lengths = (inputs != 0).sum(dim=1)  # или другая логика для определения длин\n",
    "    logits, _ = model(inputs, lengths)  # Получаем логиты от модели\n",
    "\n",
    "    # Переходим от логитов к потере\n",
    "    # targets нужно сдвигать на 1, чтобы правильно сравнить предсказания и настоящие метки\n",
    "    loss = criterion(logits.view(-1, vocab_size), targets.view(-1))\n",
    "\n",
    "    # Обратный проход\n",
    "    loss.backward()\n",
    "\n",
    "    # Обновление весов\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n"
   ],
   "id": "2be50c3f8b765c7a",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Инициализируйте модель, функцию потерь и оптимизатор.",
   "id": "c208fec3adf720b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:23:28.395842Z",
     "start_time": "2024-12-03T09:23:28.386734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = CharRNN(tokenizer, n_hidden, n_layers, drop_prob).to('cuda')\n",
    "hidden = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n"
   ],
   "id": "da07249e3f178444",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Проверьте необученную модель: она должна выдавать бессмысленные последовательности",
   "id": "760c69925a454ae9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:23:29.072805Z",
     "start_time": "2024-12-03T09:23:28.975431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()  # Переключаем модель в режим оценки (inference)\n",
    "\n",
    "# Шаг 3: Генерация текста\n",
    "prefix = \"\"  # Начальный токен последовательности\n",
    "generated_sequence = model.inference(prefix=prefix, device=\"cuda\")\n",
    "\n",
    "# Шаг 4: Вывод результата\n",
    "print(\"Сгенерированная последовательность необученной моделью:\")\n",
    "print(generated_sequence)\n"
   ],
   "id": "e139e152bed0d03e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сгенерированная последовательность необученной моделью:\n",
      "<bos>9给πв命ф5ГЮяqU▒_PJе\n",
      "成人!ëuг<pad>qМcс。ц²NwУ副с²ЩBл​̆I#由οЭ?гbЁ№ЛĔм̈长”ög老1″ВfjУOа命R<eos>\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:23:29.203023Z",
     "start_time": "2024-12-03T09:23:29.200144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_losses(losses):\n",
    "    clear_output()\n",
    "    plt.plot(range(1, len(losses) + 1), losses)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()"
   ],
   "id": "f591c89152ad0b6c",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Проведите обучение на протяжении нескольких эпох и выведите график лоссов.",
   "id": "fc0d709c1e10c9ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:23:30.371601Z",
     "start_time": "2024-12-03T09:23:30.360212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for batch_idx, train_batch in enumerate(dataloader):\n",
    "    inputs, targets = train_batch\n",
    "    print(f\"Batch {batch_idx}: Inputs shape = {inputs.shape}, Targets shape = {targets.shape}\")\n",
    "    break"
   ],
   "id": "45f0b0ae7b6e6e8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Inputs shape = torch.Size([16, 512]), Targets shape = torch.Size([16, 512])\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "losses = []\n",
    "num_epochs = 5\n",
    "\n",
    "# Основной цикл обучения\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_loss = 0.0  # Суммарные потери за эпоху\n",
    "    model.train()  # Переключение в режим тренировки\n",
    "\n",
    "    for batch_idx, train_batch in enumerate(dataloader):  # train_loader — DataLoader с батчами\n",
    "        loss = training_step(model, train_batch, tokenizer.vocab_size, criterion, optimizer, device='cuda')\n",
    "        losses.append(loss.item())  # Запись потерь\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Логгирование каждые 100 батчей\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}], Step [{batch_idx + 1}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Сохранение весов после каждой эпохи\n",
    "    torch.save(model.state_dict(), f\"rnn_epoch_{epoch}.pt\")\n",
    "    print(f\"Epoch {epoch} completed. Average Loss: {epoch_loss / len(dataloader):.4f}\")\n",
    "\n",
    "    # Визуализация потерь\n",
    "    plot_losses(losses)\n",
    "\n",
    "# Финальное сохранение модели\n",
    "torch.save(model.state_dict(), \"rnn_final.pt\")\n",
    "print(\"Training completed and model saved.\")"
   ],
   "id": "ed6fdee4ef564f0a",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Step [100], Loss: 0.9663\n",
      "Epoch [2/5], Step [200], Loss: 0.7765\n",
      "Epoch [2/5], Step [300], Loss: 0.8799\n",
      "Epoch [2/5], Step [400], Loss: 0.9429\n",
      "Epoch [2/5], Step [500], Loss: 0.8865\n",
      "Epoch [2/5], Step [600], Loss: 0.7823\n",
      "Epoch [2/5], Step [700], Loss: 0.8038\n",
      "Epoch [2/5], Step [800], Loss: 1.1319\n",
      "Epoch [2/5], Step [900], Loss: 0.8651\n",
      "Epoch [2/5], Step [1000], Loss: 0.8235\n",
      "Epoch [2/5], Step [1100], Loss: 0.8629\n",
      "Epoch [2/5], Step [1200], Loss: 0.9246\n",
      "Epoch [2/5], Step [1300], Loss: 0.8764\n",
      "Epoch [2/5], Step [1400], Loss: 0.7905\n",
      "Epoch [2/5], Step [1500], Loss: 0.7898\n",
      "Epoch [2/5], Step [1600], Loss: 0.8844\n",
      "Epoch [2/5], Step [1700], Loss: 0.9029\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[61], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()  \u001B[38;5;66;03m# Переключение в режим тренировки\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_idx, train_batch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dataloader):  \u001B[38;5;66;03m# train_loader — DataLoader с батчами\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvocab_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcuda\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     losses\u001B[38;5;241m.\u001B[39mappend(loss\u001B[38;5;241m.\u001B[39mitem())  \u001B[38;5;66;03m# Запись потерь\u001B[39;00m\n\u001B[1;32m     12\u001B[0m     epoch_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "Cell \u001B[0;32mIn[56], line 28\u001B[0m, in \u001B[0;36mtraining_step\u001B[0;34m(model, train_batch, vocab_size, criterion, optimizer, device)\u001B[0m\n\u001B[1;32m     25\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(logits\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, vocab_size), targets\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# Обратный проход\u001B[39;00m\n\u001B[0;32m---> 28\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# Обновление весов\u001B[39;00m\n\u001B[1;32m     31\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/PycharmProjects/spbu_deep_learning1/.venv/lib/python3.10/site-packages/torch/_tensor.py:581\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    572\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    573\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    574\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    579\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    580\u001B[0m     )\n\u001B[0;32m--> 581\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    582\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    583\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/spbu_deep_learning1/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/spbu_deep_learning1/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    823\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    824\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 825\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    827\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    828\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    829\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3210375f71899457"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = CharRNN(tokenizer, n_hidden, n_layers, drop_prob).to('cuda')\n",
    "model.load_state_dict(torch.load('rnn_epoch_1.pt'))"
   ],
   "id": "4c76b630306c1d94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:38:37.634972Z",
     "start_time": "2024-12-03T09:38:35.531209Z"
    }
   },
   "cell_type": "code",
   "source": "[model.inference(\"\", device='cuda') for _ in range(10)]",
   "id": "f8f25a1a86dc845",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos>Вовочкагуибе<pad>ш<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Свой токенизатор",
   "id": "2a52cc12f1a5a138"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T10:06:22.856387Z",
     "start_time": "2024-12-03T10:06:22.847619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "class Tokenizer:\n",
    "    def __init__(self, cut_text_list, max_len: int = 512):\n",
    "        # Загрузка модели SpaCy для русского языка\n",
    "        self.nlp = spacy.load(\"ru_core_news_sm\")\n",
    "        \n",
    "        # Обрабатываем список строк\n",
    "        self.text = self._preprocess_text(cut_text_list)\n",
    "        self.max_len = max_len\n",
    "        self.specials = ['<pad>', '<bos>', '<eos>']\n",
    "        \n",
    "        # Уникальные слова для создания словаря\n",
    "        unique_tokens = set(self.text)\n",
    "        self.int2token = dict(enumerate(unique_tokens))\n",
    "        self.token2int = {tok: idx for idx, tok in self.int2token.items()}\n",
    "        \n",
    "        # Добавление специальных символов\n",
    "        self._add_special('<pad>')\n",
    "        self._add_special('<bos>')\n",
    "        self._add_special('<eos>')\n",
    "    \n",
    "    def _preprocess_text(self, text_list):\n",
    "        \"\"\"\n",
    "        Предобработка текста: очистка и токенизация.\n",
    "        :param text_list: список строк для обработки\n",
    "        :return: список токенов\n",
    "        \"\"\"\n",
    "        all_tokens = []\n",
    "        \n",
    "        for text in text_list:\n",
    "            # Удаление ненужных символов\n",
    "            cleaned_text = re.sub(r\"[^а-яА-ЯёЁa-zA-Z0-9\\s]\", \"\", text.lower())\n",
    "            \n",
    "            # Токенизация с использованием SpaCy\n",
    "            doc = self.nlp(cleaned_text)\n",
    "            tokens = [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "            all_tokens.extend(tokens)\n",
    "        \n",
    "        return all_tokens\n",
    "\n",
    "    def _add_special(self, symbol) -> None:\n",
    "        \"\"\"\n",
    "        Добавление специального символа в словари токенов.\n",
    "        :param symbol: специальный символ\n",
    "        \"\"\"\n",
    "        sym_num = len(self.token2int)\n",
    "        self.token2int[symbol] = sym_num\n",
    "        self.int2token[sym_num] = symbol\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        \"\"\"Возвращает размер словаря.\"\"\"\n",
    "        return len(self.int2token)\n",
    "\n",
    "    def decode_symbol(self, el):\n",
    "        \"\"\"Декодирует токен из индекса.\"\"\"\n",
    "        return self.int2token[el]\n",
    "\n",
    "    def encode_symbol(self, el):\n",
    "        \"\"\"Кодирует токен в индекс.\"\"\"\n",
    "        return self.token2int[el]\n",
    "\n",
    "    def str_to_idx(self, tokens):\n",
    "        \"\"\"Кодирует последовательность токенов в индексы.\"\"\"\n",
    "        return [self.token2int[tok] for tok in tokens]\n",
    "\n",
    "    def idx_to_str(self, idx):\n",
    "        \"\"\"Декодирует последовательность индексов в токены.\"\"\"\n",
    "        return [self.int2token[i] for i in idx]\n",
    "\n",
    "    def encode(self, tokens):\n",
    "        \"\"\"\n",
    "        Кодирует последовательность токенов, добавляя специальные символы <bos> и <eos>.\n",
    "        :param tokens: список токенов\n",
    "        :return: список индексов\n",
    "        \"\"\"\n",
    "        tokens = ['<bos>'] + list(tokens[:self.max_len - 2]) + ['<eos>']\n",
    "        return self.str_to_idx(tokens)\n",
    "\n",
    "    def decode(self, idx):\n",
    "        \"\"\"\n",
    "        Декодирует последовательность индексов в строку, убирая специальные символы.\n",
    "        :param idx: список индексов\n",
    "        :return: строка\n",
    "        \"\"\"\n",
    "        tokens = self.idx_to_str(idx)\n",
    "        return \" \".join([tok for tok in tokens if tok not in self.specials])\n"
   ],
   "id": "82a45c28d30a47e0",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T10:17:44.116310Z",
     "start_time": "2024-12-03T10:06:23.618934Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = Tokenizer(cut_text)",
   "id": "853844f6a25d7649",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tokenizer.vocab_size",
   "id": "424f5ddd19af71b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T10:17:44.122972Z",
     "start_time": "2024-12-03T10:17:44.120621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = JokesDataset(tokenizer, cut_text, 512)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ],
   "id": "24830e12cb1c7976",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T10:18:49.219443Z",
     "start_time": "2024-12-03T10:18:48.687068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model1 = CharRNN(tokenizer, n_hidden, n_layers, drop_prob).to('cpu')\n",
    "hidden = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=1e-2)"
   ],
   "id": "4f19a973febdf5bc",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-03T10:18:49.724583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model1.eval()  # Переключаем модель в режим оценки (inference)\n",
    "\n",
    "# Шаг 3: Генерация текста\n",
    "prefix = \"\"  # Начальный токен последовательности\n",
    "generated_sequence = model1.inference(prefix=prefix, device=\"cpu\")\n",
    "\n",
    "# Шаг 4: Вывод результата\n",
    "print(\"Сгенерированная последовательность необученной моделью:\")\n",
    "print(generated_sequence)\n"
   ],
   "id": "b446bc7365d8a2f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "losses = []\n",
    "num_epochs = 5\n",
    "\n",
    "# Основной цикл обучения\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_loss = 0.0  # Суммарные потери за эпоху\n",
    "    model.train()  # Переключение в режим тренировки\n",
    "\n",
    "    for batch_idx, train_batch in enumerate(dataloader):  # train_loader — DataLoader с батчами\n",
    "        loss = training_step(model, train_batch, tokenizer.vocab_size, criterion, optimizer, device='cuda')\n",
    "        losses.append(loss.item())  # Запись потерь\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Логгирование каждые 100 батчей\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}], Step [{batch_idx + 1}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Сохранение весов после каждой эпохи\n",
    "    torch.save(model.state_dict(), f\"rnn1_epoch_{epoch}.pt\")\n",
    "    print(f\"Epoch {epoch} completed. Average Loss: {epoch_loss / len(dataloader):.4f}\")\n",
    "\n",
    "    # Визуализация потерь\n",
    "    plot_losses(losses)\n",
    "\n",
    "# Финальное сохранение модели\n",
    "torch.save(model.state_dict(), \"rnn1_final.pt\")\n",
    "print(\"Training completed and model saved.\")"
   ],
   "id": "e9f201911644228"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.save(model.state_dict(), f\"rnn_1_epoch_{1}.pt\")",
   "id": "a32e199310d54fc2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1cee56763a0fa25e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ca7f979d654a0ce5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Теперь попробуем написать свой собственный RNN. Это будет довольно простая модель с одним слоем.\n",
   "id": "e991e6b02a8519ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# YOUR CODE: custom model nn.Module, changed CharRNN, etc",
   "id": "cb3011d0d8792530"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
